{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Financial-IA — Latent Market Intelligence Demo\n",
    "\n",
    "**End-to-end demo of the Strate IV PPO agent** operating in latent space learned by Fin-JEPA.\n",
    "\n",
    "This notebook:\n",
    "1. Installs dependencies and clones the repo\n",
    "2. Downloads pre-trained checkpoints (PPO agent + trajectory buffer)\n",
    "3. Runs the agent on held-out evaluation episodes\n",
    "4. Visualizes regime switching, position management, and PnL vs Buy & Hold\n",
    "\n",
    "**No training required** — inference only (~30 seconds on CPU, ~5s on GPU).\n",
    "\n",
    "---\n",
    "> Architecture: Spherical VQ-VAE → Fin-JEPA (Mamba-2) → Stochastic Predictor → PPO Agent  \n",
    "> Paper reference: LeCun (2022) *A Path Towards Autonomous Machine Intelligence* — JEPA framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch pytorch-lightning tslearn numpy pandas dacite pyyaml einops gymnasium stable-baselines3 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone the repo (skip if already cloned)\n",
    "if not os.path.exists('World-IA-Finance'):\n",
    "    !git clone https://github.com/ElMonstroDelBrest/World-IA-Finance.git\n",
    "\n",
    "os.chdir('World-IA-Finance')\n",
    "print('Working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-header",
   "metadata": {},
   "source": [
    "## 2. Download Pre-trained Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": "import urllib.request\nimport zipfile\nfrom pathlib import Path\n\nBASE_URL = \"https://github.com/ElMonstroDelBrest/World-IA-Finance/releases/download/v1.0.0\"\n\ndef download(url, dest):\n    dest = Path(dest)\n    if dest.exists():\n        print(f'  {dest} already exists, skipping.')\n        return\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    print(f'  Downloading {dest.name}...')\n    urllib.request.urlretrieve(url, dest)\n    print(f'  Done ({dest.stat().st_size / 1e6:.1f} MB)')\n\n# PPO best model checkpoint\nprint('Downloading PPO best model...')\ndownload(\n    f\"{BASE_URL}/ppo_best_model.zip\",\n    \"checkpoints/strate_iv/ppo_best_model.zip\"\n)\n\n# Pre-computed trajectory buffer (JEPA latent representations)\nprint('Downloading trajectory buffer...')\ndownload(\n    f\"{BASE_URL}/trajectory_buffer.zip\",\n    \"/tmp/trajectory_buffer.zip\"\n)\n\n# Extract trajectory buffer\nbuf_dir = Path('data/trajectory_buffer')\nif not buf_dir.exists() or not any(buf_dir.glob('*.pt')):\n    print('Extracting trajectory buffer...')\n    with zipfile.ZipFile('/tmp/trajectory_buffer.zip', 'r') as z:\n        z.extractall('.')\n    print(f'  Extracted {len(list(buf_dir.glob(\"*.pt\")))} episodes')\nelse:\n    print(f'  Buffer already extracted: {len(list(buf_dir.glob(\"*.pt\")))} episodes')\n\nprint('\\nAll assets ready.')\n"
  },
  {
   "cell_type": "markdown",
   "id": "demo-header",
   "metadata": {},
   "source": [
    "## 3. Run Agent Demo\n",
    "\n",
    "The PPO agent operates on **latent observations** — not raw prices. Each step, it receives:\n",
    "- The JEPA context encoding of past market regimes\n",
    "- A distribution of N=16 stochastic future trajectories\n",
    "- Its current position and cumulative PnL\n",
    "\n",
    "It outputs a continuous action in `[-1, 1]` (short → flat → long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-demo",
   "metadata": {},
   "outputs": [],
   "source": "import sys, os\nsys.path.insert(0, '.')\n\nimport matplotlib\nmatplotlib.use('Agg')\nimport numpy as np\nfrom pathlib import Path\nfrom IPython.display import display, Image\n\nfrom stable_baselines3 import PPO\nfrom src.strate_iv.config import load_config\nfrom src.strate_iv.env import LatentCryptoEnv\nfrom src.strate_iv.trajectory_buffer import TrajectoryBuffer\nfrom scripts.demo_results import run_episode, plot_demo\n\n# Load config and buffer\nconfig = load_config('configs/strate_iv.yaml')\nbuffer = TrajectoryBuffer('data/trajectory_buffer/')\n_, eval_buffer = buffer.split(val_ratio=config.buffer.val_ratio)\nprint(f'Eval buffer: {len(eval_buffer)} episodes')\n\n# Load PPO best model\nmodel_path = 'checkpoints/strate_iv/ppo_best_model.zip'\nmodel = PPO.load(model_path)\nexpected_obs_dim = model.observation_space.shape[0]\nprint(f'PPO best model loaded — obs dim: {expected_obs_dim}')\n\n# Create environment\nenv = LatentCryptoEnv(buffer=eval_buffer, config=config.env)\nprint(f'Environment obs dim: {env.observation_space.shape[0]}')\nprint(f'Window: {config.env.n_tgt} patches × {config.env.patch_len} candles = {config.env.n_tgt * config.env.patch_len}h')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-episodes",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nfrom pathlib import Path\nfrom src.strate_iv.trajectory_buffer import TrajectoryEntry\nfrom src.strate_iv import EPS\n\n# Patch env to use the original 416-dim obs (commit 8fd6ad2)\n# Original obs: h_x_pooled + future_mean(global) + future_std(global)\n#             + close_stats + revin_stds + delta_mu + position + cum_pnl\ndef _build_observation_from_compat(self, entry, step_idx=0, realized_idx=0,\n                                    position=0.0, cum_pnl=0.0):\n    future_latents = entry.future_latents.numpy()       # (N, N_tgt, d_model)\n    h_x_pooled    = entry.h_x_pooled.numpy()            # (d_model,)\n    future_mean   = future_latents.mean(axis=0).mean(axis=0)  # global mean\n    future_std    = future_latents.std(axis=0).mean(axis=0)   # global std\n    close_stats   = self._compute_close_stats(entry.future_ohlcv.numpy())\n    revin_stds    = entry.revin_stds.numpy().flatten()\n    delta_mu      = self._compute_delta_mu(entry, self.config.patch_len)\n    pos           = np.array([position],  dtype=np.float32)\n    cpnl          = np.array([cum_pnl],   dtype=np.float32)\n\n    obs = np.concatenate([\n        h_x_pooled, future_mean, future_std,\n        close_stats, revin_stds, delta_mu,\n        pos, cpnl,\n    ]).astype(np.float32)\n    return np.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)\n\nimport types\nenv._build_observation_from = types.MethodType(_build_observation_from_compat, env)\nprint(f'Obs dim after patch: {env._build_observation_from(env.buffer.entries[0]).shape[0]}')\n\n# Run episodes using exact scripts/demo_results.py logic\nPath('outputs/demo').mkdir(parents=True, exist_ok=True)\nn_demos = 5\nresults = []\n\nprint(f'\\nRunning {n_demos} episodes...\\n')\nfor i in range(n_demos):\n    traj = run_episode(model, env, seed=None)\n    out_path = f'outputs/demo/demo_{i:02d}.png'\n    plot_demo(traj, out_path)\n    results.append((out_path, traj))\n    print(f'  Episode {i+1}: actions = {traj[\"actions\"].round(2).tolist()}')\n"
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-results",
   "metadata": {},
   "outputs": [],
   "source": "from IPython.display import display, Image\n\nfor i, (out_path, traj) in enumerate(results):\n    print(f'\\n--- Episode {i+1} | actions = {traj[\"actions\"].round(2).tolist()} ---')\n    display(Image(filename=out_path, width=900))\n"
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "### What you just saw\n",
    "\n",
    "The agent **never sees raw prices** during inference. It operates entirely on latent representations produced by Fin-JEPA:\n",
    "\n",
    "| Component | Role |\n",
    "|---|---|\n",
    "| **Spherical VQ-VAE** (Strate I) | Tokenizes OHLCV patches → discrete market regime tokens |\n",
    "| **Fin-JEPA + Mamba-2** (Strate II) | Self-supervised temporal model over token sequences |\n",
    "| **Stochastic Predictor** (Strate III) | Samples N=16 divergent future latent trajectories |\n",
    "| **PPO Agent** (Strate IV) | Plans in latent space, outputs continuous position [-1, 1] |\n",
    "\n",
    "### Why this matters\n",
    "\n",
    "Classical approaches (LSTM, Transformer on raw prices) are forced to predict **every tick** — memorizing noise instead of learning structure.  \n",
    "JEPA learns to predict **latent representations** of future states, ignoring unpredictable details.  \n",
    "The agent then plans in this cleaner latent space, exhibiting genuine **regime switching** rather than curve-fitting.\n",
    "\n",
    "---\n",
    "\n",
    "**Repository:** https://github.com/ElMonstroDelBrest/World-IA-Finance  \n",
    "**License:** AGPL-3.0"
   ]
  }
 ]
}